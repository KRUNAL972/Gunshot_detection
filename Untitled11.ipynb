{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfMAqmohtsOD",
        "outputId": "579ec00d-62c4-4984-b721-2dbcd8ef5263"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from resampy) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.11/dist-packages (from resampy) (0.61.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53->resampy) (0.44.0)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import resampy\n",
        "print(resampy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjNxv_kruviG",
        "outputId": "f67ad15d-1b00-44a4-828f-0f17c51e5071"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM-pzBMmuzP4",
        "outputId": "e48c5f57-0127-4081-860e-5da3245800af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall librosa\n",
        "# !pip install librosa\n"
      ],
      "metadata": {
        "id": "0zUQbI6Ru3le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unRg5EXDfkuC",
        "outputId": "3e35d54f-2306-4388-e08e-307ce41ca8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rupakroy/urban-sound-8k?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.61G/5.61G [01:17<00:00, 78.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/rupakroy/urban-sound-8k/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rupakroy/urban-sound-8k\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(path + \"/UrbanSound8K.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "gPwg4vS-n1cd",
        "outputId": "8feeb858-0d85-4455-fb8e-14b404884538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de127ab4-6b74-4bc4-a77a-9a24dea5374c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de127ab4-6b74-4bc4-a77a-9a24dea5374c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de127ab4-6b74-4bc4-a77a-9a24dea5374c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de127ab4-6b74-4bc4-a77a-9a24dea5374c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-599eb214-31cc-436e-991e-e46eccd6fc12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-599eb214-31cc-436e-991e-e46eccd6fc12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-599eb214-31cc-436e-991e-e46eccd6fc12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8732,\n  \"fields\": [\n    {\n      \"column\": \"slice_file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8732,\n        \"samples\": [\n          \"54898-8-0-2.wav\",\n          \"172338-9-0-7.wav\",\n          \"95562-4-3-0.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fsID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57991,\n        \"min\": 344,\n        \"max\": 209992,\n        \"num_unique_values\": 1297,\n        \"samples\": [\n          180257,\n          157940,\n          20015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74.29212630755417,\n        \"min\": 0.0,\n        \"max\": 600.125356,\n        \"num_unique_values\": 4878,\n        \"samples\": [\n          10.038318,\n          5.711988,\n          4.634753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74.36966935075809,\n        \"min\": 0.105962,\n        \"max\": 604.125356,\n        \"num_unique_values\": 5020,\n        \"samples\": [\n          13.168347,\n          2.653802,\n          10.286916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          3,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"jackhammer\",\n          \"children_playing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "j_iyVGxAn1Y1",
        "outputId": "42619599-884b-4426-8f13-0c68bb4029ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "dog_bark            1000\n",
              "children_playing    1000\n",
              "air_conditioner     1000\n",
              "street_music        1000\n",
              "jackhammer          1000\n",
              "engine_idling       1000\n",
              "drilling            1000\n",
              "siren                929\n",
              "car_horn             429\n",
              "gun_shot             374\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dog_bark</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children_playing</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>air_conditioner</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>street_music</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jackhammer</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>engine_idling</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drilling</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>siren</th>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>car_horn</th>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gun_shot</th>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['gunshot'] = df['class'].apply(lambda x: 1 if x == 'gun_shot' else 0)\n",
        "\n",
        "# Verify label distribution\n",
        "print(df['gunshot'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CO604EZn1WH",
        "outputId": "ae679819-b981-46f3-ab5f-1e2a63baefe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gunshot\n",
            "0    8358\n",
            "1     374\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df[df['gunshot'] == 0]\n",
        "df_minority = df[df['gunshot'] == 1]\n",
        "\n",
        "# Undersample majority class\n",
        "df_majority_downsampled = df_majority.sample(n=len(df_minority) * 3, random_state=42)\n",
        "\n",
        "# Combine balanced dataset\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Verify new class distribution\n",
        "print(df_balanced['gunshot'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws7jptpOowxf",
        "outputId": "b6e61d8a-2917-4a79-949b-609839e5ee67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gunshot\n",
            "0    1122\n",
            "1     374\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_PATH = os.path.join(path, \"UrbanSound8K\")"
      ],
      "metadata": {
        "id": "olcJKNd1uJ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_PATH = os.path.join(AUDIO_PATH, \"UrbanSound8K\", \"audio\")\n"
      ],
      "metadata": {
        "id": "Gu_PVJrzqkUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(AUDIO_PATH):\n",
        "    print(\"✅ 'audio' folder exists. Listing folds...\")\n",
        "    print(os.listdir(AUDIO_PATH))  # Should list ['fold1', 'fold2', ..., 'fold10']\n",
        "else:\n",
        "    print(\"❌ ERROR: 'audio' folder NOT found in\", AUDIO_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgJhwsYqqxzb",
        "outputId": "ba42c686-1b76-44e3-9079-668260c6606e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 'audio' folder exists. Listing folds...\n",
            "['fold7', 'fold1', 'fold3', 'fold10', 'fold5', 'fold4', 'fold8', 'fold2', 'fold6', 'fold9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_path(row):\n",
        "    return os.path.join(AUDIO_PATH, f\"fold{row['fold']}\", row[\"slice_file_name\"])\n",
        "\n",
        "df[\"file_path\"] = df.apply(get_audio_path, axis=1)\n",
        "\n",
        "# Verify corrected paths\n",
        "print(df[[\"slice_file_name\", \"fold\", \"file_path\"]].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Wc435Iq1De",
        "outputId": "0dda8f53-de62-4e1f-e186-10f0dd500d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      slice_file_name  fold                                          file_path\n",
            "0    100032-3-0-0.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "1  100263-2-0-117.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "2  100263-2-0-121.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "3  100263-2-0-126.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "4  100263-2-0-137.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "5  100263-2-0-143.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "6  100263-2-0-161.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "7    100263-2-0-3.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "8   100263-2-0-36.wav     5  /root/.cache/kagglehub/datasets/rupakroy/urban...\n",
            "9    100648-1-0-0.wav    10  /root/.cache/kagglehub/datasets/rupakroy/urban...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to extract MFCC features\n",
        "def extract_features(file_path, n_mfcc=13, max_pad_length=40):\n",
        "    \"\"\"\n",
        "    Extracts MFCC features from an audio file and pads/truncates them to a fixed length.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, res_type=\"kaiser_fast\")\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "\n",
        "        # Pad or truncate to ensure fixed size\n",
        "        pad_width = max_pad_length - mfccs.shape[1]\n",
        "        if pad_width > 0:\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode=\"constant\")\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_pad_length]\n",
        "\n",
        "        return mfccs.flatten()  # Convert 2D MFCC to 1D vector\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define paths for saving features and labels\n",
        "FEATURES_PATH = \"features.pkl\"\n",
        "LABELS_PATH = \"labels.pkl\"\n",
        "\n",
        "# Check if features and labels are already saved\n",
        "if os.path.exists(FEATURES_PATH) and os.path.exists(LABELS_PATH):\n",
        "    print(\"Loading features and labels from disk...\")\n",
        "    with open(FEATURES_PATH, \"rb\") as f:\n",
        "        features = pickle.load(f)\n",
        "    with open(LABELS_PATH, \"rb\") as f:\n",
        "        labels = pickle.load(f)\n",
        "else:\n",
        "    # Extract features from all files\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"Extracting MFCC features...\")\n",
        "    for _, row in df.iterrows():\n",
        "        file_path = os.path.join(AUDIO_PATH, f\"fold{row['fold']}\", row[\"slice_file_name\"])\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            mfcc = extract_features(file_path)\n",
        "            if mfcc is not None:\n",
        "                features.append(mfcc)\n",
        "                labels.append(row[\"gunshot\"])\n",
        "        else:\n",
        "            print(f\"Skipping missing file: {file_path}\")\n",
        "\n",
        "    # Save features and labels to disk\n",
        "    with open(FEATURES_PATH, \"wb\") as f:\n",
        "        pickle.dump(features, f)\n",
        "    with open(LABELS_PATH, \"wb\") as f:\n",
        "        pickle.dump(labels, f)\n",
        "    print(\"Features and labels saved to disk.\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(f\"Feature extraction complete. Shape: {X.shape}, Labels: {y.shape}\")\n",
        "\n",
        "# Split dataset into 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training Samples: {X_train.shape[0]}, Testing Samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4eZb4Qq41u",
        "outputId": "7852c41a-1878-4831-acc2-4aaba16e277b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MFCC features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and labels saved to disk.\n",
            "Feature extraction complete. Shape: (8732, 520), Labels: (8732,)\n",
            "Training Samples: 6985, Testing Samples: 1747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# Save features and labels\n",
        "dump(features, \"features.joblib\")\n",
        "dump(labels, \"labels.joblib\")\n",
        "\n",
        "# Load features and labels\n",
        "features = load(\"features.joblib\")\n",
        "labels = load(\"labels.joblib\")"
      ],
      "metadata": {
        "id": "goFdwHtd0Nhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training Samples: {X_train.shape[0]}, Testing Samples: {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndx3SU_XrJ1K",
        "outputId": "2758a011-56ef-4fc6-fca2-3c23af51fc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples: 6985, Testing Samples: 1747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build a simple feedforward neural network\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stop],\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate performance\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK6L7Nj9y1OY",
        "outputId": "ea1a1d2f-6e34-45b5-9027-1dd223160036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9195 - loss: 4.1398 - val_accuracy: 0.9782 - val_loss: 0.1343\n",
            "Epoch 2/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.4760 - val_accuracy: 0.9760 - val_loss: 0.2058\n",
            "Epoch 3/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.2695 - val_accuracy: 0.9840 - val_loss: 0.0771\n",
            "Epoch 4/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.2103 - val_accuracy: 0.9880 - val_loss: 0.0448\n",
            "Epoch 5/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.1587 - val_accuracy: 0.9794 - val_loss: 0.0829\n",
            "Epoch 6/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.1220 - val_accuracy: 0.9914 - val_loss: 0.0325\n",
            "Epoch 7/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0851 - val_accuracy: 0.9874 - val_loss: 0.0494\n",
            "Epoch 8/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.1132 - val_accuracy: 0.9880 - val_loss: 0.0331\n",
            "Epoch 9/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0604 - val_accuracy: 0.9908 - val_loss: 0.0395\n",
            "Epoch 10/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0542 - val_accuracy: 0.9914 - val_loss: 0.0341\n",
            "Epoch 11/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0639 - val_accuracy: 0.9891 - val_loss: 0.0306\n",
            "Epoch 12/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0647 - val_accuracy: 0.9943 - val_loss: 0.0283\n",
            "Epoch 13/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0725 - val_accuracy: 0.9920 - val_loss: 0.0244\n",
            "Epoch 14/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0512 - val_accuracy: 0.9937 - val_loss: 0.0218\n",
            "Epoch 15/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0403 - val_accuracy: 0.9920 - val_loss: 0.0267\n",
            "Epoch 16/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0386 - val_accuracy: 0.9931 - val_loss: 0.0240\n",
            "Epoch 17/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0422 - val_accuracy: 0.9943 - val_loss: 0.0323\n",
            "Epoch 18/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0358 - val_accuracy: 0.9926 - val_loss: 0.0202\n",
            "Epoch 19/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0266 - val_accuracy: 0.9920 - val_loss: 0.0283\n",
            "Epoch 20/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0478 - val_accuracy: 0.9908 - val_loss: 0.0246\n",
            "Epoch 21/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0486 - val_accuracy: 0.9931 - val_loss: 0.0274\n",
            "Epoch 22/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0552 - val_accuracy: 0.9903 - val_loss: 0.0378\n",
            "Epoch 23/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0553 - val_accuracy: 0.9948 - val_loss: 0.0190\n",
            "Epoch 24/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0279 - val_accuracy: 0.9891 - val_loss: 0.0277\n",
            "Epoch 25/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0305 - val_accuracy: 0.9874 - val_loss: 0.0436\n",
            "Epoch 26/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0415 - val_accuracy: 0.9943 - val_loss: 0.0245\n",
            "Epoch 27/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0366 - val_accuracy: 0.9903 - val_loss: 0.0316\n",
            "Epoch 28/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0372 - val_accuracy: 0.9943 - val_loss: 0.0168\n",
            "Epoch 29/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0229 - val_accuracy: 0.9920 - val_loss: 0.0203\n",
            "Epoch 30/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0256 - val_accuracy: 0.9954 - val_loss: 0.0260\n",
            "Epoch 31/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.9954 - val_loss: 0.0210\n",
            "Epoch 32/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0208 - val_accuracy: 0.9943 - val_loss: 0.0176\n",
            "Epoch 33/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0153 - val_accuracy: 0.9943 - val_loss: 0.0191\n",
            "Test Accuracy: 99.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # If using softmax, otherwise use a threshold\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Gunshot\", \"Gunshot\"], yticklabels=[\"Non-Gunshot\", \"Gunshot\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "3covjF-Yy582",
        "outputId": "9f3084ba-8995-4599-95f3-fd323874b5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"gunshot_detection_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcWI0qOe6rpi",
        "outputId": "5ce41613-ef48-4a18-87a0-d3bf8c642c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved Keras model\n",
        "model = tf.keras.models.load_model(\"gunshot_detection_model.h5\")\n",
        "\n",
        "# Convert the model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"gunshot_detection_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model converted to TFLite and saved as gunshot_detection_model.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1T7D-Wp6yAe",
        "outputId": "b5fcf714-92b4-4c69-d868-6cdfaca67ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpn_qrm1k7'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 520), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136638486767248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486770320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486762256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486760528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486762064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486763216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486761296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486770704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model converted to TFLite and saved as gunshot_detection_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Enable default optimizations\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "# Save the quantized TFLite model\n",
        "with open(\"gunshot_detection_model_quantized.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_quantized_model)\n",
        "\n",
        "print(\"Quantized TFLite model saved as gunshot_detection_model_quantized.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgPTHvGj678q",
        "outputId": "376e0f04-d6b2-4f76-efbb-c5cb1ce3c759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpx69efyqx'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 520), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136638486767248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486770320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486762256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486760528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486762064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486763216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486761296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136638486770704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Quantized TFLite model saved as gunshot_detection_model_quantized.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Load the original Keras model\n",
        "keras_model = load_model(\"gunshot_detection_model.h5\")\n",
        "\n",
        "# Load the TensorFlow Lite models\n",
        "tflite_model = tflite.Interpreter(model_path=\"gunshot_detection_model.tflite\")\n",
        "tflite_quantized_model = tflite.Interpreter(model_path=\"gunshot_detection_model_quantized.tflite\")\n",
        "\n",
        "# Allocate tensors for both TFLite models\n",
        "tflite_model.allocate_tensors()\n",
        "tflite_quantized_model.allocate_tensors()\n",
        "\n",
        "# Function to convert input to TFLite format\n",
        "def predict_tflite(interpreter, input_data):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Set the input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Evaluate Keras model\n",
        "print(\"Evaluating Keras model...\")\n",
        "y_pred_keras = keras_model.predict(X_test)\n",
        "y_pred_keras = (y_pred_keras > 0.5).astype(int)  # Convert to binary predictions\n",
        "\n",
        "# Evaluate TensorFlow Lite model (Non-quantized)\n",
        "print(\"Evaluating TensorFlow Lite model...\")\n",
        "y_pred_tflite = []\n",
        "for sample in X_test:\n",
        "    sample_input = np.expand_dims(sample, axis=0).astype(np.float32)\n",
        "    output = predict_tflite(tflite_model, sample_input)\n",
        "    y_pred_tflite.append(np.argmax(output))\n",
        "\n",
        "y_pred_tflite = np.array(y_pred_tflite)\n",
        "\n",
        "# Evaluate TensorFlow Lite quantized model\n",
        "print(\"Evaluating TensorFlow Lite quantized model...\")\n",
        "y_pred_tflite_quant = []\n",
        "for sample in X_test:\n",
        "    sample_input = np.expand_dims(sample, axis=0).astype(np.float32)\n",
        "    output = predict_tflite(tflite_quantized_model, sample_input)\n",
        "    y_pred_tflite_quant.append(np.argmax(output))\n",
        "\n",
        "y_pred_tflite_quant = np.array(y_pred_tflite_quant)\n",
        "\n",
        "# Compare performance using accuracy\n",
        "accuracy_keras = accuracy_score(y_test, y_pred_keras)\n",
        "accuracy_tflite = accuracy_score(y_test, y_pred_tflite)\n",
        "accuracy_tflite_quant = accuracy_score(y_test, y_pred_tflite_quant)\n",
        "\n",
        "print(f\"Accuracy of Keras model: {accuracy_keras * 100:.2f}%\")\n",
        "print(f\"Accuracy of TensorFlow Lite model: {accuracy_tflite * 100:.2f}%\")\n",
        "print(f\"Accuracy of Quantized TensorFlow Lite model: {accuracy_tflite_quant * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF0BL9Hh7DUI",
        "outputId": "c2ae578f-7c52-4203-f163-75e4b3792e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Keras model...\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Evaluating TensorFlow Lite model...\n",
            "Evaluating TensorFlow Lite quantized model...\n",
            "Accuracy of Keras model: 99.43%\n",
            "Accuracy of TensorFlow Lite model: 95.71%\n",
            "Accuracy of Quantized TensorFlow Lite model: 95.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to get the size of a file in MB\n",
        "def get_model_size(model_path):\n",
        "    model_size = os.path.getsize(model_path) / (1024 * 1024)  # Size in MB\n",
        "    return model_size\n",
        "\n",
        "# Load the Keras model\n",
        "keras_model = tf.keras.models.load_model(\"gunshot_detection_model.h5\")\n",
        "\n",
        "# Get the size of the Keras model file\n",
        "keras_model_size = get_model_size(\"gunshot_detection_model.h5\")\n",
        "\n",
        "# Get the number of parameters in the Keras model\n",
        "keras_model_params = keras_model.count_params()\n",
        "\n",
        "# Get the size of the TensorFlow Lite model file (non-quantized)\n",
        "tflite_model_size = get_model_size(\"gunshot_detection_model.tflite\")\n",
        "\n",
        "# Get the size of the quantized TensorFlow Lite model file\n",
        "tflite_quantized_model_size = get_model_size(\"gunshot_detection_model_quantized.tflite\")\n",
        "\n",
        "# Print out the details\n",
        "print(f\"Size of Keras model: {keras_model_size:.2f} MB\")\n",
        "print(f\"Number of parameters in Keras model: {keras_model_params}\")\n",
        "print(f\"Size of TensorFlow Lite model (non-quantized): {tflite_model_size:.2f} MB\")\n",
        "print(f\"Size of TensorFlow Lite model (quantized): {tflite_quantized_model_size:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVfJTOyf-Rdo",
        "outputId": "65cfc429-eaba-41d8-9b4c-b389bd1a2f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Keras model: 2.03 MB\n",
            "Number of parameters in Keras model: 174593\n",
            "Size of TensorFlow Lite model (non-quantized): 0.67 MB\n",
            "Size of TensorFlow Lite model (quantized): 0.18 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4BSdV3Z-ptU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}